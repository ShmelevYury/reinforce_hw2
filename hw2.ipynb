{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS, N_COLS, N_WIN = 3, 3, 3\n",
    "\n",
    "class PI:\n",
    "    def __init__(self, Q, epsilon, alpha, gamma):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.last_q = 0\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        \n",
    "    def getActionGreedy(self, s, n=None):\n",
    "        return np.argmax(Q[s])\n",
    "    \n",
    "    def get_epsillon_greedy(self, state, possible_moves, action_to_int):\n",
    "        if (np.random.random() > self.epsilon):\n",
    "            action = self.getActionGreedy(state)\n",
    "        else:\n",
    "            index = np.random.randint(0, high=possible_moves.shape[0])\n",
    "            action = action_to_int(possible_moves[index])\n",
    "        \n",
    "        self.last_action = action\n",
    "        self.last_state = state\n",
    "        self.last_q = self.Q[self.last_state][self.last_action]\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def update_Q(self, reward, state):\n",
    "        if self.last_state is not None:\n",
    "            self.Q[self.last_state][self.last_action] = self.last_q + self.alpha * (reward + self.gamma * np.max(Q[state]) - self.last_q)\n",
    "    \n",
    "\n",
    "class TicTacToe(gym.Env):\n",
    "    def __init__(self, n_rows=N_ROWS, n_cols=N_COLS, n_win=N_WIN):\n",
    "        self.n_rows = n_rows\n",
    "        self.n_cols = n_cols\n",
    "        self.n_win = n_win\n",
    "\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.gameOver = False\n",
    "        self.boardHash = None\n",
    "        # ход первого игрока\n",
    "        self.curTurn = 1\n",
    "        self.emptySpaces = None\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def getEmptySpaces(self):\n",
    "        if self.emptySpaces is None:\n",
    "            res = np.where(self.board == 0)\n",
    "            self.emptySpaces = np.array([ (i, j) for i,j in zip(res[0], res[1]) ])\n",
    "        return self.emptySpaces\n",
    "\n",
    "    def makeMove(self, player, i, j):\n",
    "        self.board[i, j] = player\n",
    "        self.emptySpaces = None\n",
    "        self.boardHash = None\n",
    "\n",
    "    def getHash(self):\n",
    "        if self.boardHash is None:\n",
    "            self.boardHash = ''.join(['%s' % (x+1) for x in self.board.reshape(self.n_rows * self.n_cols)])\n",
    "        return self.boardHash\n",
    "\n",
    "    def isTerminal(self):\n",
    "        # проверим, не закончилась ли игра\n",
    "        cur_marks, cur_p = np.where(self.board == self.curTurn), self.curTurn\n",
    "        for i,j in zip(cur_marks[0], cur_marks[1]):\n",
    "#             print((i,j))\n",
    "            win = False\n",
    "            if i <= self.n_rows - self.n_win:\n",
    "                if np.all(self.board[i:i+self.n_win, j] == cur_p):\n",
    "                    win = True\n",
    "            if not win:\n",
    "                if j <= self.n_cols - self.n_win:\n",
    "                    if np.all(self.board[i,j:j+self.n_win] == cur_p):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j <= self.n_cols - self.n_win:\n",
    "                    if np.all(np.array([ self.board[i+k,j+k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j >= self.n_win-1:\n",
    "                    if np.all(np.array([ self.board[i+k,j-k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if win:\n",
    "                self.gameOver = True\n",
    "                return self.curTurn\n",
    "\n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "\n",
    "        self.gameOver = False\n",
    "        return None\n",
    "\n",
    "    def printBoard(self):\n",
    "        for i in range(0, self.n_rows):\n",
    "            print('----'*(self.n_cols)+'-')\n",
    "            out = '| '\n",
    "            for j in range(0, self.n_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----'*(self.n_cols)+'-')\n",
    "\n",
    "    def getState(self):\n",
    "        return (self.getHash(), self.getEmptySpaces(), self.curTurn)\n",
    "\n",
    "    def action_from_int(self, action_int):\n",
    "        return ( int(action_int / self.n_cols), int(action_int % self.n_cols))\n",
    "\n",
    "    def int_from_action(self, action):\n",
    "        return action[0] * self.n_cols + action[1]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.board[action[0], action[1]] != 0:\n",
    "            return self.getState(), -10, True, {}\n",
    "        self.makeMove(self.curTurn, action[0], action[1])\n",
    "        reward = self.isTerminal()\n",
    "        self.curTurn = -self.curTurn\n",
    "        return self.getState(), 0 if reward is None else reward, reward is not None, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.boardHash = None\n",
    "        self.gameOver = False\n",
    "        self.emptySpaces = None\n",
    "        self.curTurn = 1\n",
    "        \n",
    "    def get_random_Q(self, verbose=False):\n",
    "        Q = {}\n",
    "        iter_object = product('012', repeat=self.n_cols * self.n_rows)\n",
    "        if verbose:\n",
    "            iter_object = tqdm(iter_object)\n",
    "            \n",
    "        for s in iter_object:\n",
    "            s = ''.join(s)\n",
    "            Q[s] = []\n",
    "            for i in s:\n",
    "                if i == '1':\n",
    "                    Q[s].append(np.random.random() * 0.5)\n",
    "                else:\n",
    "                    Q[s].append(float('-inf'))\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToe(n_rows=3, n_cols=3, n_win=3)\n",
    "env.printBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 1 cur_turn: -1\n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "| o | x |   | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "obs, reward, done, info = env.step((2,2))\n",
    "state, possible_moves, cur_turn = obs\n",
    "print('reward:', reward, 'cur_turn:', cur_turn)\n",
    "env.printBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning_episode(env, pi1=None, pi2=None):\n",
    "    assert pi1 != None or pi2 != None\n",
    "    \n",
    "    env.reset()\n",
    "    state, possible_moves, cur_turn = env.getState()\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        if cur_turn == 1:\n",
    "            if pi1 is None:\n",
    "                index = np.random.randint(0, high=possible_moves.shape[0])\n",
    "                action = env.int_from_action(possible_moves[index])\n",
    "            else:\n",
    "                action = pi1.get_epsillon_greedy(state, possible_moves, env.int_from_action)\n",
    "        else:\n",
    "            if pi2 is None:\n",
    "                index = np.random.randint(0, high=possible_moves.shape[0])\n",
    "                action = env.int_from_action(possible_moves[index])\n",
    "            else:\n",
    "                action = pi2.get_epsillon_greedy(state, possible_moves, env.int_from_action)\n",
    "        \n",
    "        obs, reward, done, info = env.step(env.action_from_int(action)) \n",
    "        assert reward != -10\n",
    "        \n",
    "        if reward == 0:\n",
    "            if cur_turn == 1:\n",
    "                if pi2 is not None:\n",
    "                    pi2.update_Q(reward, state)\n",
    "            else:\n",
    "                if pi1 is not None:\n",
    "                    pi1.update_Q(reward, state)\n",
    "        else:\n",
    "            if pi1 is not None:\n",
    "                pi1.update_Q(reward * cur_turn, state)\n",
    "            if pi2 is not None:\n",
    "                pi2.update_Q(reward * -cur_turn, state)\n",
    "            \n",
    "        state, possible_moves, cur_turn = obs\n",
    "        \n",
    "    return reward\n",
    "        \n",
    "def play_game(env, pi1, pi2, verbose=False):\n",
    "    env.reset()\n",
    "    state, possible_moves, cur_turn = env.getState()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        if cur_turn == 1:\n",
    "            action = pi1.getActionGreedy(state)\n",
    "        else:\n",
    "            action = pi2.getActionGreedy(state)\n",
    "\n",
    "        obs, reward, done, info = env.step(env.action_from_int(action))\n",
    "        state, possible_moves, cur_turn = obs\n",
    "        \n",
    "        if verbose:\n",
    "            env.printBoard()\n",
    "            print(env.getHash())\n",
    "        \n",
    "        assert reward != -10\n",
    "        \n",
    "    return reward\n",
    "        \n",
    "def eval_players(env, pi1, pi2, n=10000):\n",
    "    pi1_wins = 0\n",
    "    pi2_wins = 0\n",
    "    draws = 0\n",
    "    for _ in range(n):\n",
    "        reward = play_game(env, pi1, pi2)\n",
    "            \n",
    "        if reward == 1:\n",
    "            pi1_wins += 1\n",
    "        elif reward == -1:\n",
    "            pi2_wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "        \n",
    "    return pi1_wins / n, pi2_wins / n, draws / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f827cc643a014b3cb0bd0d561bf295af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.232, p2: 0.333\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.209, p2: 0.3185\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.1965, p2: 0.2865\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.2325, p2: 0.278\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.2005, p2: 0.2965\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.216, p2: 0.2605\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.2235, p2: 0.3175\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.224, p2: 0.2975\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.2105, p2: 0.2755\n",
      "Cur test stat: p1: 0.0, p2: 0.0, draw: 1.0\n",
      "Cur train stat: p1: 0.2305, p2: 0.267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToe(n_rows=3, n_cols=3, n_win=3)\n",
    "n = 20 * 1000\n",
    "epsillon = 0.1\n",
    "gamma = 0.9\n",
    "alpha = 0.3\n",
    "verbose_rate = 0.1\n",
    "n_test = 10000\n",
    "\n",
    "Q = env.get_random_Q()\n",
    "pi1 = PI(copy.deepcopy(Q), epsillon, alpha, gamma)\n",
    "pi2 = PI(copy.deepcopy(Q), epsillon, alpha, gamma)\n",
    "\n",
    "test_rewards = []\n",
    "train_rewards = []\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    pi1_reward = Q_learning_episode(env, pi1=pi1)\n",
    "    pi2_reward = Q_learning_episode(env, pi2=pi2)\n",
    "    \n",
    "    train_rewards.append((pi1_reward, pi2_reward))\n",
    "    test_rewards.append(eval_players(env, pi1, pi2, n=1))\n",
    "    \n",
    "    if i % int(n * verbose_rate) == int(n * verbose_rate) - 1:\n",
    "        cur_stat = np.asarray(test_rewards[-int(n * verbose_rate):]).mean(axis=0)\n",
    "        print(f'Cur test stat: p1: {cur_stat[0]}, p2: {cur_stat[1]}, draw: {cur_stat[2]}', flush=True)\n",
    "        cur_stat = np.asarray(train_rewards[-int(n * verbose_rate):]).mean(axis=0)\n",
    "        print(f'Cur train stat: p1: {cur_stat[0]}, p2: {cur_stat[1]}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-inf,\n",
       " -inf,\n",
       " -inf,\n",
       " 0.30061531676374553,\n",
       " -inf,\n",
       " -inf,\n",
       " 0.3209665146735112,\n",
       " 0.43266186603856965,\n",
       " 0.1769221997612736]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi2.Q['220102111']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "111112111\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "110112111\n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "210112111\n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "210102111\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "220102111\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "220102101\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "220102102\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "220002102\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "220002202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_game(env, pi1, pi2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
